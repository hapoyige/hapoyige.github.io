<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title></title>
      <link href="/2018/06/29/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%9C%9F%E6%9C%AB%20Tweet%20popularity%20prediction/"/>
      <url>/2018/06/29/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%9C%9F%E6%9C%AB%20Tweet%20popularity%20prediction/</url>
      <content type="html"><![CDATA[<h1 id="数据挖掘期末-Tweet-popularity-prediction"><a href="#数据挖掘期末-Tweet-popularity-prediction" class="headerlink" title="数据挖掘期末 Tweet popularity prediction"></a>数据挖掘期末 Tweet popularity prediction</h1><h2 id="成员及分工"><a href="#成员及分工" class="headerlink" title="成员及分工"></a>成员及分工</h2><p>陈宏俊(10152510101)  特征工程、部分传统机器学习模型</p><p>徐嘉欣(10152510228)  数据预处理、特征工程、LFM模型</p><p>汤旭东(10152510104)  数据预处理、MOOD调试、HFT模型</p><p>联系方式： <a href="mailto:851988701@qq.com" target="_blank" rel="noopener">851988701@qq.com</a></p><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>根据一些历史数据，预测某用户发的某条tweet在将来的流行度，其中流行度 $popularity=log(retweet count)$ </p><h2 id="模型和过程"><a href="#模型和过程" class="headerlink" title="模型和过程"></a>模型和过程</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>hashtags,text都转为数字,去掉url和文本中的hashtags.</p><p><img src="D:\Major\大三下\期末pj_CCIR2018\tweet\汇报\data_prepro.png" alt="data_prepro"></p><h3 id="传统机器学习方法"><a href="#传统机器学习方法" class="headerlink" title="传统机器学习方法"></a>传统机器学习方法</h3><h4 id="不考虑文本信息"><a href="#不考虑文本信息" class="headerlink" title="不考虑文本信息"></a>不考虑文本信息</h4><p>考虑发布者的属性:status count,follwers count,推文的属性:hashtags, 含url的条数(url可能包含图片视频等更丰富的信息)，hashtags属性可用one hot编码（一共只有413个tags）,可进行PCA降维。</p><h5 id="sklearn中的一些回归方法"><a href="#sklearn中的一些回归方法" class="headerlink" title="sklearn中的一些回归方法"></a>sklearn中的一些回归方法</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">增添一个特征：作者的tweet平均关注度（followers_count/statuses_count）。这么做的原因是考虑到增加一个新的维度来衡量作者的影响力。以上的三个作者信息以及tweet的tags、和text共同构成了训练集和验证集的特征空间。</span><br><span class="line">   此处的tags因为是一个不定长的list，为了能够统一为定长的特征，将其所有出现过的tags进行统计，发现有413个，因此构建出一个413维的tags空间，每个tweet的tags出现一次就在对应位置加1，为了便于减少稀疏度和提高效率，将所有tweet的tags构成的矩阵进行pca降维，降至5维。</span><br></pre></td></tr></table></figure><p><img src="D:\Major\大三下\期末pj_CCIR2018\tweet\汇报\junjun.png" alt="junjun"></p><h5 id="LR中当作多个回归任务"><a href="#LR中当作多个回归任务" class="headerlink" title="LR中当作多个回归任务"></a>LR中当作多个回归任务</h5><p>为每个用户构建一个LR回归器，用各自的用户数据进行训练，发现MSE&gt;3，不优于单个回归器，猜测由于每个用户的训练数据不足导致。</p><h5 id="LFM"><a href="#LFM" class="headerlink" title="LFM"></a>LFM</h5><p><img src="D:\Major\大三下\期末pj_CCIR2018\tweet\汇报\xin_small.png" alt="xin_small"></p><p>MSE=2.2</p><h5 id="基于用户的协同过滤"><a href="#基于用户的协同过滤" class="headerlink" title="基于用户的协同过滤"></a>基于用户的协同过滤</h5><p>考虑用户和hashtags之间的相互影响，由于用户往往在同一tag下发过多条tweet,这里的score取平均值。</p><p>由于score受到用户followers影响比较明显，引入influence=score/log(followers).</p><p>采用皮尔逊相似度。但实现中发现取非常相似的用户做类别才能取得好一些的效果，所谓非常相似，实际上是基于对应用户的历史记录了（用户之前在相应tag下发过tweet）</p><p><img src="D:\Major\大三下\期末pj_CCIR2018\tweet\汇报\CF_res.png" alt="CF_res"></p><h4 id="考虑文本信息"><a href="#考虑文本信息" class="headerlink" title="考虑文本信息"></a>考虑文本信息</h4><p>#####　TFIDF编码+PCA降维</p><p>在LR模型上测试，总词数10000+，PCA降维至200</p><p>MSE=2.65，也并无提升。</p><h5 id="HFT模型"><a href="#HFT模型" class="headerlink" title="HFT模型"></a>HFT模型</h5><p>参考文章：<strong>Hidden Factors and Hidden Topics:Understanding Rating Dimensions with Review Text，Julian McAuley，Jure Leskovec</strong></p><p>这第二次作业的方法用在这儿略显生硬了，原因和协同过滤一样:tags多次出现。</p><h6 id="简要介绍"><a href="#简要介绍" class="headerlink" title="简要介绍"></a>简要介绍</h6><p>•LDA</p><p>•认为文档是这样形成的：1.随机选一个主题。2.在这个主题下随机选择属于这个主题的词汇。其中主题和主题的词汇都满足狄利克雷分布。目标是极大化似然</p><p>$$p(\tau|\theta,\phi,z)=\prod_{d\in\tau}\prod_{j=1}^{N_d}\theta_{d,z_{d,j}}\phi_{z_{d,j},w_{d,j}}$$</p><p>$w_{d,j}$表示文档d第j个词，$z_{d,j}$表示文档d第j个词属于哪个主题。$\theta_{d,k}$表示$\theta_d$属于主题k的概率，$\phi_{k,w}$表示词汇w属于主题k的概率。</p><p>•LFM中γi的维度和LDA中$\theta_d$的维度应该是一样的，它们都表示被用户们讨论的不同主题的个数！</p><p>•考虑到 $\theta_d$是一个分布，这样定义它们的正相关关系：</p><p>$$\theta_{i,k}=\frac{exp(\kappa\gamma_{i,k})}{\sum_{k’}exp(\kappa\gamma_{i,k’})}$$</p><p>•这样HFT要最小化的目标函数：</p><p>$$f(\tau|\theta,\phi,\kappa,z)=\sum_{r_{u,i}\in\tau}\underbrace{(rec(u,i)-r_{u,i})^2}<em>{rating \ error}-\mu\underbrace{l(\tau|\theta,\phi,z)}</em>{corpus \ likelihood}$$</p><p>•其中对LDA的似然取了对数</p><p>•关于如何训练模型，采用一种类似EM算法的策略：</p><p><img src="D:\Major\大三下\期末pj_CCIR2018\tweet\汇报\HFT_train.png" alt="HFT_train"></p><p>•其中(7)采用L-BFGS，一种拟牛顿方法。(8)根据(7)的结果进行topic assignment.</p><h3 id="深度学习方法"><a href="#深度学习方法" class="headerlink" title="深度学习方法"></a>深度学习方法</h3><p>参考文章: <strong>Factorization Meets Memory Network:Learning to Predict Activity Popularity, Wen Wang, Wei Zhang  and Jun Wang</strong></p><h4 id="主要的网络结构"><a href="#主要的网络结构" class="headerlink" title="主要的网络结构"></a>主要的网络结构</h4><p><img src="D:\Major\大三下\期末pj_CCIR2018\tweet\汇报\mood.png" alt="mood"></p><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p>{u,q,d,r}:user,location,document,rating</p><p>其中 rating=log(retweet_count)</p><h4 id="关键步骤"><a href="#关键步骤" class="headerlink" title="关键步骤"></a>关键步骤</h4><p>认为每个词，出现在不同的用户的tweet中，在网络中会有不同的权重。</p><p>$$\omega_{v(j)}^{u,q}=(u_u^A+q_q^A)\top e_{v(j)}$$</p><p>更大的权重表示词v(j)和用户、相应地点的关联性越大。</p><p>作为网络的输入，用softmax归一化:</p><p>$p_{v(j)}^{u,q}=softmax(w_{v(j)}^{u,q})$  ,  $o=\sum_jp_{v(j)}^{u,q}f_{v(j)}$</p><p>拓展到多层网络中:</p><p>$$u_u^{A,k+1}=u_u^{A,k}+o^k$$</p><p>$$q_u^{A,k+1}=q_u^{A,k}+o^k$$</p><p>$$o_d=o^K+u_u^{A,K}+q^{A,K}_q$$</p><p>向量表示和最终预测:</p><p>$$\psi_d^{u,q}=u_u^I\odot q_q^I+u_u^I\odot o_d+q_q^I\odot o_d$$</p><p>$$\hat{r}=\theta\top \delta(W_1^T[\psi_d^{u,q};u_u^B;q_q^B]+b_1)+b$$</p><h4 id="应用到当前问题"><a href="#应用到当前问题" class="headerlink" title="应用到当前问题"></a>应用到当前问题</h4><p>文章解决的问题，和手头数据集比，多了location信息，少了hashtags信息，但location是一维的，hashtags可能有多维。处理时对hashtags取平均或随机选一个，效果差不多。</p><h4 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h4><p>出乎意料地，该模型达到了很好的效果，最终的预测文件也由该模型生成。向深度学习低头。</p><p><img src="D:\Major\大三下\期末pj_CCIR2018\tweet\DL_result.png" alt="DL_result"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>​    小组成员各抒己见，尝试了自己的模型，但鲜有能跑出好效果的模型（无法优于论文中的深度学习模型），也不奇怪，毕竟是当前比较热门的研究方向，有一定难度。</p><p>​    大家对数据预处理、特征工程的理解更深了，也更熟悉了sklearn的一些有用模块，收获颇丰。</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title></title>
      <link href="/2018/06/25/pyspark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2018/06/25/pyspark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h1 id="pyspark学习笔记"><a href="#pyspark学习笔记" class="headerlink" title="pyspark学习笔记"></a>pyspark学习笔记</h1><p>主要看的书是 《PySpark实战指南》 机械工业出版社的。</p><h2 id="第一章-了解Spark"><a href="#第一章-了解Spark" class="headerlink" title="第一章  了解Spark"></a>第一章  了解Spark</h2><h3 id="弹性分布式数据集-RDD"><a href="#弹性分布式数据集-RDD" class="headerlink" title="弹性分布式数据集 RDD"></a>弹性分布式数据集 RDD</h3>]]></content>
      
      
    </entry>
    
    <entry>
      <title>math_test</title>
      <link href="/2018/06/07/math-test/"/>
      <url>/2018/06/07/math-test/</url>
      <content type="html"><![CDATA[<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script><p>$$\underbrace{f(x) = a_1x^n + a_2x^{n-1} + a_3x^{n-2}}_{22}$$<br>$e^{\alpha+1+\beta}\in$<br>$a_1^2$<br>$e^{x^2}$<br>${e^x}^2$</p><p>测试一下数学公式ok不ok了</p>]]></content>
      
      
        <tags>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>半吊子的人，不幸福</title>
      <link href="/2018/06/01/%E5%8D%8A%E5%90%8A%E5%AD%90%E7%9A%84%E4%BA%BA%EF%BC%8C%E4%B8%8D%E5%B9%B8%E7%A6%8F/"/>
      <url>/2018/06/01/%E5%8D%8A%E5%90%8A%E5%AD%90%E7%9A%84%E4%BA%BA%EF%BC%8C%E4%B8%8D%E5%B9%B8%E7%A6%8F/</url>
      <content type="html"><![CDATA[<p>#半吊子的人，不幸福</p><p>记得蛮久以前刷知乎的时候看到过这句话,有种心头一震的感觉。查了一下，是《奇葩说》里黄执中说的。我应该就是这样半吊子的人吧。和身边很多人不一样，他们的生活很有节奏感，很有<strong>年轻的活力</strong>，比如肝DDL的时候就疯狂熬夜，通过某事或庆祝成功的时候也能玩得很疯。我想这或许是大都市的主流节奏吧：凌晨的上海，路边的烧烤店一家连着一家，生意兴隆。但我想不会总是一批人，他们是在庆祝吧，或者说偶尔的放肆。我也曾在这样的摊子驻留，和同学朋友们喝酒吹牛（主要是他们吹）。但总是不能完全放开，喝酒又喝不醉，是很难受的，这样几次之后我都会尽量避免这样的活动。</p><p>我在学习或者工作上的<strong>爆发力</strong>也不够强。因为熬夜着实让我很难受…可能的话会尽量早点准备大到比如期末考试，小到某次作业这样的东西。但总有失算的时候…遇到这种时候我一般会象征性地熬夜，然后“<strong>放了</strong>”，后果的严重性起不了很大的作用，我也不是很明白。关于小事的话，早开始准备可能会比他人多花时间、多踩坑吧，多花时间可能是因为压力小，效率就上不去，多踩坑一般是因为…老师又改了要求什么的。很多同学是靠DDL激发自己的潜能，高效完成任务。我至今没有学会这种模式。</p><p>但我是否不喜欢这种大起大落的生活，要过平平淡淡、波澜不惊的<strong>佛系人生</strong>呢？其实此刻我心里也没有主意。人啊，贱。过一段平静的生活，又会想找点刺激。然后就会陷入第一段所说的那样：感觉自己不是那样的人，<strong>放不开</strong>，玩得也不尽兴。为什么不尽兴？有时是想着将来的打算的原因，感觉这次玩耍又浪费了时间金钱…有时候不知是什么原因。然后又回归佛系的生活，等待下一次循环…</p><p>前段时间（五一）和老友聊天，HL说他生活经验丰富的老妈在我小时候就看出来我，踏实XX*FFGG(一些好话)，但是以后可能会缺少<strong>生活的激情</strong>，哈哈，不得不佩服她眼光的毒辣吧，好像还真被说准了。那我以后是慢慢寻找生活的激情呢，还是怎样呢？也罢，各人有各人的活法，走着瞧吧。</p>]]></content>
      
      
        <tags>
            
            <tag> 生活 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>python缩进s错误</title>
      <link href="/2018/06/01/python%E7%BC%A9%E8%BF%9B%E9%94%99%E8%AF%AF/"/>
      <url>/2018/06/01/python%E7%BC%A9%E8%BF%9B%E9%94%99%E8%AF%AF/</url>
      <content type="html"><![CDATA[<p><em>IndentationError: unindent does not match any outer indentation level</em></p><p><em>TabError: inconsistent use of tabs and spaces in indentation</em></p><p>可能出现这两个报错</p><p>这是由于代码中四个空格和Tab混搭造成的，经常由文件传输、格式转换、编辑器之类的原因造成。比如转换中自动把Tab变成了四个空格。我遇到的场景是作业中补全代码的时候，直接在notePad++里面改，我自己用的\t，但是其余代码是四空格，引发了错误，也没想到很好的办法，好在代码也不长，就直接对用空格的地方选中，Tab，Shift+Tab，全部改了过来。同时也了解了NotePad++看这些制表符的方法：</p><p>菜单里面：    视图-》显示符号——》显示空格与制表符        </p><p>这样可以看到哪些地方是tab哪些地方是空格。</p><img src="/2018/06/01/python缩进错误/Image.png">]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 编辑器 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>python中JSON序列化错误</title>
      <link href="/2018/05/31/python%E4%B8%ADJSON%E5%BA%8F%E5%88%97%E5%8C%96%E9%94%99%E8%AF%AF/"/>
      <url>/2018/05/31/python%E4%B8%ADJSON%E5%BA%8F%E5%88%97%E5%8C%96%E9%94%99%E8%AF%AF/</url>
      <content type="html"><![CDATA[<p><em>TypeError: 0 is not JSON serializable</em></p><p>0怎么就不能序列化了呢？查资料发现可能是数据类型的原因，代码中，这个0的数据类型并不是python自带的，而是np.int64之类的。加个类型转换int()即可。</p><p>参考：<a href="https://stackoverflow.com/questions/11942364/typeerror-integer-is-not-json-serializable-when-serializing-json-in-python" target="_blank" rel="noopener">https://stackoverflow.com/questions/11942364/typeerror-integer-is-not-json-serializable-when-serializing-json-in-python</a></p>]]></content>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> json </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hello World!</title>
      <link href="/2018/05/25/hello-world/"/>
      <url>/2018/05/25/hello-world/</url>
      <content type="html"><![CDATA[<p>##Hello World!</p><p>试着开始写博客啦，记录一些coding的问题和生活感悟等等等等…感谢<strong>bl Feng</strong>在建站过程的指点.</p><p>本站还有待完善：</p><ul><li>搜索功能</li><li>评论功能</li><li>个人信息</li></ul><p>此条博客也作为发布文章的测试。</p>]]></content>
      
      
        <tags>
            
            <tag> 生活 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
